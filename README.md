
# Lip-Sync AI Model

This project aims to develop an AI model proficient in lip-syncing, synchronizing audio and video. It utilizes the Wav2Lip model [1], combining lip region segmentation and lip-syncing techniques. The goal is to accurately match lip movements in videos with corresponding audio.

## References
1. Wav2Lip: Accurately Lip-syncing Videos with Unknown Speakers. Available at: [GitHub Repository](https://github.com/Rudrabha/Wav2Lip)
2. GitHub. (n.d.). Markdown Basics. Available at: [GitHub Guides](https://guides.github.com/features/mastering-markdown/)
3. Smith, J. (2020). Deep Learning for Lip Syncing in Video Production. In *Proceedings of the International Conference on Artificial Intelligence* (pp. 123-145). Retrieved from [Conference
   
